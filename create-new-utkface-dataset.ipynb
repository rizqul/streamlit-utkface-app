{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2236229,"sourceType":"datasetVersion","datasetId":1343616}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\n\n# Configuration\nIMAGE_SIZE = 224\nBATCH_SIZE = 32\nEPOCHS = 20\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# DATA_DIR = '/kaggle/input/utkface-new/crop_part1' # Update this path!\nDATA_DIR = '/kaggle/input/utkface-uncropped-dataset/Images'\n\nprint(DEVICE)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-21T12:07:13.830794Z","iopub.execute_input":"2026-01-21T12:07:13.831105Z","iopub.status.idle":"2026-01-21T12:07:17.369250Z","shell.execute_reply.started":"2026-01-21T12:07:13.831079Z","shell.execute_reply":"2026-01-21T12:07:17.368487Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install retina-face","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T12:07:17.370729Z","iopub.execute_input":"2026-01-21T12:07:17.371082Z","iopub.status.idle":"2026-01-21T12:07:21.698620Z","shell.execute_reply.started":"2026-01-21T12:07:17.371057Z","shell.execute_reply":"2026-01-21T12:07:21.697687Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2\nfrom retinaface import RetinaFace\nfaces = RetinaFace.extract_faces(img_path = \"/kaggle/input/utkface-uncropped-dataset/Images/29_0_1_20170113154817089.jpg\", align=True)\n\nfor face in faces:\n  plt.imshow(face)\n  plt.show()\n\nfaces_2 = RetinaFace.detect_faces(\"/kaggle/input/utkface-uncropped-dataset/Images/29_0_1_20170113154817089.jpg\")\n# print(faces_2['face_1']['facial_area'])\nprint(type(faces_2))\n\nimg = cv2.imread(\"/kaggle/input/utkface-uncropped-dataset/Images/29_0_1_20170113154817089.jpg\")\nplt.imshow(img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T12:07:21.699866Z","iopub.execute_input":"2026-01-21T12:07:21.700158Z","iopub.status.idle":"2026-01-21T12:07:45.180238Z","shell.execute_reply.started":"2026-01-21T12:07:21.700131Z","shell.execute_reply":"2026-01-21T12:07:45.179452Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom retinaface import RetinaFace\nfrom PIL import Image\nimport math\n\ndef align_face(img, left_eye, right_eye):\n    \"\"\"\n    Rotates the image to make the line between eyes horizontal.\n    Returns: rotated_img, rotation_matrix, new_center\n    \"\"\"\n    # 1. Calculate angle\n    dY = right_eye[1] - left_eye[1]\n    dX = right_eye[0] - left_eye[0]\n    angle = np.degrees(np.arctan2(dY, dX)) \n    \n    # 2. Get rotation matrix\n    h, w = img.shape[:2]\n    center = (w // 2, h // 2)\n    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n    \n    # 3. Rotate Image\n    # Calculate new bounding dimensions to avoid cropping after rotation\n    cos = np.abs(M[0, 0])\n    sin = np.abs(M[0, 1])\n    new_w = int((h * sin) + (w * cos))\n    new_h = int((h * cos) + (w * sin))\n    \n    # Adjust matrix translation\n    M[0, 2] += (new_w / 2) - center[0]\n    M[1, 2] += (new_h / 2) - center[1]\n    \n    rotated_img = cv2.warpAffine(img, M, (new_w, new_h))\n    return rotated_img, M\n\ndef transform_point(point, M):\n    \"\"\"Applies affine transform to a single (x, y) point.\"\"\"\n    v = [point[0], point[1], 1]\n    transformed = np.dot(M, v)\n    return (int(transformed[0]), int(transformed[1]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T12:07:45.181116Z","iopub.execute_input":"2026-01-21T12:07:45.181433Z","iopub.status.idle":"2026-01-21T12:07:45.189334Z","shell.execute_reply.started":"2026-01-21T12:07:45.181410Z","shell.execute_reply":"2026-01-21T12:07:45.188562Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def align_face(img, left_eye, right_eye):\n    # left_eye = Person's Left Eye (Image Right)\n    # right_eye = Person's Right Eye (Image Left)\n    \n    # We want vector from Image Left -> Image Right\n    # So: Person's Left Eye - Person's Right Eye\n    dY = left_eye[1] - right_eye[1]\n    dX = left_eye[0] - right_eye[0]\n    \n    angle = np.degrees(np.arctan2(dY, dX))\n    \n    # 2. Get rotation matrix\n    h, w = img.shape[:2]\n    center = (w // 2, h // 2)\n    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n    \n    # 3. Rotate Image\n    cos = np.abs(M[0, 0])\n    sin = np.abs(M[0, 1])\n    new_w = int((h * sin) + (w * cos))\n    new_h = int((h * cos) + (w * sin))\n    \n    M[0, 2] += (new_w / 2) - center[0]\n    M[1, 2] += (new_h / 2) - center[1]\n    \n    rotated_img = cv2.warpAffine(img, M, (new_w, new_h))\n    return rotated_img, M","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T12:07:45.191159Z","iopub.execute_input":"2026-01-21T12:07:45.191894Z","iopub.status.idle":"2026-01-21T12:07:45.203644Z","shell.execute_reply.started":"2026-01-21T12:07:45.191865Z","shell.execute_reply":"2026-01-21T12:07:45.202692Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CROP 3 SIDE -> ROTATE (normal)","metadata":{}},{"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\nimport math\nfrom retinaface import RetinaFace\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\n# Configuration\nINPUT_DIR = \"/kaggle/input/utkface-uncropped-dataset/Images\"\nOUTPUT_DIR = \"/kaggle/working/cropped-utkface\"\nCSV_OUTPUT_PATH = \"/kaggle/working/skipped_images.csv\" # <--- CHANGE 2: Define CSV path\nMARGIN = 0.2\nTARGET_SIZE = (224, 224) \n\n\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n    \n# images_all = os.listdir(INPUT_DIR)\n# print(len(images_all))\n\nimages = [f for f in os.listdir(INPUT_DIR) if f.endswith(('.jpg', '.png', '.jpeg'))]\nprint(type(images[0]))\n\nbad_images = [\n    '1_1_0_20170109190459034.jpg',\n    '35_0_1_20170113155220675.jpg',\n    '29_0_1_20170113154817089.jpg',\n    '27_0_0_20170117175751139.jpg',\n    '90_0_2_20170111211411216.jpg',\n    '20_0_1_20170117012858687.jpg',\n    '28_0_1_20170113180639429.jpg',\n    '90_0_2_20170111210008312.jpg',\n    '2_0_3_20161220144926901.jpg',\n    '12_1_2_20170103201240488.jpg',\n]\n\nLIMIT = 0\nskipped_files = []\n\nfor img_name in tqdm(images):\n    # if LIMIT > 10:\n    #     break\n\n    img_name = img_name.strip()\n    img_path = os.path.join(INPUT_DIR, img_name)\n    \n    faces = RetinaFace.detect_faces(img_path)\n    \n    if not faces:\n        img_no_faces = cv2.imread(img_path)\n        cv2.imwrite(os.path.join(OUTPUT_DIR, img_name), img_no_faces)\n        \n        skipped_files.append({'filename':img_name})\n        continue\n        \n    face_data = faces['face_1']\n    landmarks = face_data['landmarks']\n    bbox = face_data['facial_area'] \n    \n    # 2. Get Eye Coordinates & Face Center\n    left_eye_img = landmarks[\"left_eye\"]   # Person's left eye (on image right)\n    right_eye_img = landmarks[\"right_eye\"] # Person's right eye (on image left)\n    \n    x1, y1, x2, y2 = bbox\n    face_w = x2 - x1\n    face_h = y2 - y1\n    face_cx = x1 + (face_w // 2)\n    face_cy = y1 + (face_h // 2)\n    \n    # 3. Calculate Rotation Angle\n    dy = left_eye_img[1] - right_eye_img[1]\n    dx = left_eye_img[0] - right_eye_img[0]\n    angle = np.degrees(np.arctan2(dy, dx)) \n    \n    # ---------------------------------------------------------\n    # 4. Calculate Scale (Modified for Top/Side Margins only)\n    # ---------------------------------------------------------\n    # Width needs margin on Left + Right (2 * MARGIN)\n    target_w_box = face_w * (1 + MARGIN * 2)\n    \n    # Height needs margin on Top ONLY (1 * MARGIN)\n    target_h_box = face_h * (1 + MARGIN)\n    \n    # We choose the max dimension to ensure the face fits inside\n    desired_size = max(target_w_box, target_h_box)\n    scale = TARGET_SIZE[0] / desired_size\n    \n    # ---------------------------------------------------------\n    # 5. Build the Affine Matrix (Modified to shift face down)\n    # ---------------------------------------------------------\n    center = (float(face_cx), float(face_cy))\n    M = cv2.getRotationMatrix2D(center, angle, scale)\n    \n    # Standard centering (moves face center to image center)\n    t_x = (TARGET_SIZE[0] / 2) - face_cx\n    t_y = (TARGET_SIZE[1] / 2) - face_cy\n    \n    # SHIFT CORRECTION:\n    # Because we added margin to Top but NOT Bottom, the logical center \n    # of our crop is higher up on the face. To center that \"high point\",\n    # we must push the face DOWN in the final image.\n    # The shift amount is exactly half the margin height in pixels.\n    shift_y = (face_h * MARGIN * 0.5) * scale\n    \n    M[0, 2] += t_x\n    M[1, 2] += t_y + shift_y  # Add positive Y to move image down\n    \n    # 6. Apply Warp\n    img = cv2.imread(img_path)\n    aligned_face = cv2.warpAffine(img, M, TARGET_SIZE, flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0))\n    \n    # Visualization\n    # plt.figure(figsize=(10, 5))\n    # plt.subplot(1, 2, 1)\n    # plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    # plt.title(\"Original\")\n    \n    # plt.subplot(1, 2, 2)\n    # plt.imshow(cv2.cvtColor(aligned_face, cv2.COLOR_BGR2RGB))\n    # plt.title(\"Aligned (Top Margin Only)\")\n    # plt.show()\n\n    cv2.imwrite(os.path.join(OUTPUT_DIR, img_name), aligned_face)\n    \n    LIMIT += 1\n\nprint(\"IMAGE COUNT : \" + str(LIMIT))\n\ndf_skipped = pd.DataFrame(skipped_files)\ndf_skipped.to_csv(CSV_OUTPUT_PATH, index=False)\nprint(f\"Skipped files saved to: {CSV_OUTPUT_PATH}\")\n\nprint(\"Preprocessing Complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T12:07:47.830956Z","iopub.execute_input":"2026-01-21T12:07:47.831756Z","iopub.status.idle":"2026-01-21T12:08:05.417298Z","shell.execute_reply.started":"2026-01-21T12:07:47.831729Z","shell.execute_reply":"2026-01-21T12:08:05.416510Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\n# Define the source folder path and the desired output zip file name (without the extension)\nsource_dir = OUTPUT_DIR\noutput_zip_name = 'utkface-croped-margin20' # This will create 'my_project_archive.zip'\n\nif not os.path.exists(output_zip_name + '.zip'):\n    shutil.make_archive(output_zip_name, 'zip', source_dir)    \n    print(f\"Folder '{source_dir}' successfully zipped to '{output_zip_name}.zip'\")\nelse:\n    print(f\"file already exist\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T08:16:00.822691Z","iopub.execute_input":"2026-01-12T08:16:00.822947Z","iopub.status.idle":"2026-01-12T08:16:00.871831Z","shell.execute_reply.started":"2026-01-12T08:16:00.822926Z","shell.execute_reply":"2026-01-12T08:16:00.871141Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}